{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381c6d14-e10d-4996-bd01-e743208644d6",
   "metadata": {},
   "source": [
    "The goal of this notebook is to show you how you can use W&B Registry to track, share, and use dataset and model artifacts in your machine learning workflow by you and other members of your organization. By the end of this notebook, you will know how to use W&B to:\n",
    "\n",
    "1. Create a [custom registry](https://docs.wandb.ai/guides/registry/create_registry)\n",
    "2. Create [collections](https://docs.wandb.ai/guides/registry/create_collection) within our registry\n",
    "3. Make our dataset and model artifacts available to other members of our organization. \n",
    "4. See how to download artifacts from the registry for inference\n",
    "\n",
    "To do this, we will create a basic neural network to classify the biological class of animals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f92cd-90ff-41cc-a656-2502799a1989",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ee0c6-4e88-4c77-9cf5-dde109bb7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb torch ucimlrepo scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c6701-7375-4bb0-a70f-3fdc5bff1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import wandb\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fecd29-8146-41e2-86fb-0bb4e3e3350a",
   "metadata": {},
   "source": [
    "## Retrieve and process dataset\n",
    "We will use the open source [Zoo dataset](https://archive.ics.uci.edu/dataset/111/zoo) from the UCI Machine Learning Repository.\n",
    "\n",
    "### Retrieve dataset\n",
    "We can either manually download the dataset or use the [`ucimlrepo` package](https://github.com/uci-ml-repo/ucimlrepo) to import the dataset directly into our notebook. For this example, we will go with the latter and import the dataset directly into this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1fc39-c06f-468c-82ad-736ca764e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = zoo.data.features \n",
    "y = zoo.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137a521-ced5-4e35-88d0-b6245527cb90",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb34ad-02df-4256-b5de-6058c2826305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features: \", X.shape, \"type: \", type(X))\n",
    "print(\"labels: \", y.shape, \"type: \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2f7c4-7db7-4d09-9850-e7c6121ab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4df0-120b-4915-8f88-c9d36637cbfc",
   "metadata": {},
   "source": [
    "### Process data\n",
    "\n",
    "Most of the major processing was already done for us (no missing values, normalized, etc.). For training we are going to convert our dataset from pandas DataFrames to tensores, convert the data type of our input tensotre to match the data type of the nn.Linear module, and convert our labels tensor to index from 0-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff90527-d818-4678-bf01-3efe4c8c58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type of the data must match the data type of the model, the default dtype for nn.Linear is torch.float32\n",
    "dataset = torch.tensor(X.values).type(torch.float32) \n",
    "\n",
    "# Convert to tensor and format labels from 0 - 6 for indexing\n",
    "labels = torch.tensor(y.values)  - 1\n",
    "\n",
    "print(\"dataset: \", dataset.shape, \"dtype: \",dataset.dtype)\n",
    "print(\"labels: \", labels.shape, \"dtype: \",labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce3c7c-193c-4c5a-90e6-ad278ff17154",
   "metadata": {},
   "source": [
    "Save processed dataset locally using [`torch.save`](https://pytorch.org/docs/stable/generated/torch.save.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dacfb7-7493-4d36-8167-212f8b51af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, \"zoo_dataset.pt\")\n",
    "torch.save(labels, \"zoo_labels.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb001f4b-b9a2-4fb4-9b8b-d943536d3e08",
   "metadata": {},
   "source": [
    "## Create a registry for our dataset and models\n",
    "\n",
    "Let's create a registry to organize both our dataset artifacts and (at a later step) our model artifacts. To do this, navigate to the Registry App in the W&B App UI:\n",
    "\n",
    "2. Within Custom registry, click on the **Create registry** button.\n",
    "3. Provide a name for your registry in the **Name** field. For this example, we will name our registry \"Zoo_Classifier\".\n",
    "4. Optionally provide a description about the registry.\n",
    "5. From the [**Registry visibility**](https://docs.wandb.ai/guides/registry/configure_registry#registry-visibility-types) dropdown, click select \"Organization\".\n",
    "6. Select \"All types\" from the **Accepted artifacts** type dropdown.\n",
    "7. Click on the **Create registry** button.\n",
    "\n",
    "\n",
    "Note: You do not need to use one registry for organizing and tracking different types of artifacts. Another popular choice is to create a regsitry specifically for datasets, a registry specifically for models, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d6427-4244-4504-a40d-bdb6bdbc8758",
   "metadata": {},
   "source": [
    "## Track and publish dataset \n",
    "\n",
    "Within our \"Zoo_Classifier\" we will create a collection called \"Datasets\". A collection is a set of linked artifact versions in a registry. In this example we will create two collections: one for our datasets and one for our models. First, let's create a collection for our datasets. To create a collection we need to do two things:\n",
    "\n",
    "1. Specify the full path name where we want to store our artifact. \n",
    "   * The full paht name consists of: `{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}`\n",
    "2. Use the `run.link_artifact` method and pass our artifact object and full path name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe847c-9229-4428-873b-bde5d0c654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"zoo_experiment\"\n",
    "TEAM_ENTITY = \"smle-reg-team-2\"\n",
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"Zoo_Classifier\"\n",
    "COLLECTION_NAME = \"Datasets\"\n",
    "\n",
    "target_path=f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "print(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c237c-1e8d-4c2e-8ac4-8221146d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=TEAM_ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=\"upload_dataset\"\n",
    ")\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"zoo_dataset\",\n",
    "    type=\"dataset\"\n",
    ")\n",
    "\n",
    "artifact.add_file(local_path=\"zoo_dataset.pt\", name=\"zoo_dataset\")\n",
    "artifact.add_file(local_path=\"zoo_labels.pt\", name=\"zoo_labels\")\n",
    "\n",
    "run.link_artifact(artifact=artifact, target_path=target_path)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383bc963-55f9-498c-b42d-a2a0bf86f3b7",
   "metadata": {},
   "source": [
    "### Split data\n",
    "Split the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243bcd0-c3bc-4958-bb62-4ac129cbaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the train test split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset,labels, random_state=42,test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3492dc4-f465-4843-b573-0b2ca752b0ac",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28053a-73c5-4ef4-a308-0c255c25595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=16 , out_features=16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=16, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c289cfc-eec8-49dc-8d93-9bd188c40545",
   "metadata": {},
   "source": [
    "### Define hyperparameters, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6486b-8d3a-43c6-b97e-66308b64e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epochs\": 1000,\n",
    "    \"model_type\": \"Multivariate_neural_network_classifier\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485e9d4-01db-40b2-ae3d-1c7c7d1c45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hyperparameter_config[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f6942-e8e9-4429-9f26-e00fbdf8b338",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Train model, save model, store model as an artifact in W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042375b-c2c8-4503-9888-a406bc9c5df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = wandb.init(entity = TEAM_ENTITY, project = PROJECT, job_type = \"training\", config = hyperparameter_config)\n",
    "\n",
    "# Training loop\n",
    "for e in range(hyperparameter_config[\"epochs\"]):\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred, y_train.squeeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    wandb.log({\n",
    "            \"train/epoch_ndx\": e,\n",
    "            \"train/train_loss\": loss\n",
    "        })\n",
    "\n",
    "    # Evaluate model\n",
    "\n",
    "    # Checkpoint model\n",
    "    if e % 99 == 1:\n",
    "        print(\"epoch: \", e,\"loss:\", loss.item())\n",
    "    \n",
    "        ## Checkpoint model\n",
    "        PATH = 'zoo_wandb.pth' \n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "        artifact = wandb.Artifact(\n",
    "            name=f\"zoo-{wandb.run.id}\",\n",
    "            type=\"model\",\n",
    "            metadata={\n",
    "                \"num_classes\": 7,\n",
    "                \"model_type\": wandb.config[\"model_type\"]\n",
    "            }\n",
    "        )\n",
    "        # Add artifact file\n",
    "        artifact.add_file(PATH)\n",
    "        artifact.save()\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85c431-fcc6-4dcd-919b-56568cc5db2b",
   "metadata": {},
   "source": [
    "## Publish model to the registry\n",
    "Let's make this model artifact available to other users in our organization. To do this, we will create another collection within our Zoo_Classifier registry.\n",
    "\n",
    "To create a collection within our registry, we will need to get the full name (or path) of our model artifact. Go to the W&B App UI and find the full name of the model artifact you want to link to the registry:\n",
    "\n",
    "1. Click on the **Artifacts** tab\n",
    "2. Select the name of the artifact within the left navbar\n",
    "3. Click on the **Version** tab\n",
    "4. Within the **Version overview**, you will find the full name of your artifact. Make note of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0524f8-6c37-4f79-bb1e-f9e0418b4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"Zoo_Classifier\"\n",
    "COLLECTION_NAME = \"Trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec22dd2-83a5-4ba1-8c2d-130263b51fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path=f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "print(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ed37c-f488-4cd8-8797-fdeb6002148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)\n",
    "name=\"smle-reg-team-2/zoo_experiment/zoo-nhqnys3o:v10\"\n",
    "model_artifact = run.use_artifact(artifact_or_name=name, type=\"model\")\n",
    "run.link_artifact(artifact=model_artifact, target_path=target_path)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da2c69-dc5d-451b-b709-fe2822a9811c",
   "metadata": {},
   "source": [
    "## Download artifacts from registry for inference\n",
    "\n",
    "For this last section, suppose you are a different user. This user wants to take take the model and dataset that you pushed to the registry and make predictions on a new test set. Also suppose that this user has [member role permissions](https://docs.wandb.ai/guides/registry/configure_registry#registry-roles-permissions) which means they can view and download artifacts from our registry.\n",
    "\n",
    "How can this person get your artifacts that you published to the registry? Simple:\n",
    "\n",
    "1. Know the path of the artifact in the registry\n",
    "2. Use the W&B Python SDK to download the artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7cfe-eef0-478d-9898-95067e37d572",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d258c-ed08-47f0-afca-8a2a50bb0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)\n",
    "name=\"smle-registries-bug-bash/wandb-registry-Zoo_Classifier/Trained_models:v0\"\n",
    "registry_model = run.use_artifact(artifact_or_name=name)\n",
    "local_model_path = registry_model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43394e-d596-4b97-947f-0314649ac0cb",
   "metadata": {},
   "source": [
    "For PyTorch models, we need to redefine our model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a3118-747d-4a44-a906-3d3eff41df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = NeuralNetwork()\n",
    "loaded_model.load_state_dict(torch.load(f=local_model_path + \"/zoo_wandb.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93895213-e75e-46e6-b3a8-8017ccaff9e2",
   "metadata": {},
   "source": [
    "### Get dataset from registry\n",
    "\n",
    "Let's get the dataset from our registry. For this example, we will download the dataset and use the same random seed to get our test set and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa34f51-fbe5-4a41-9e69-da6ea9ce943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"smle-registries-bug-bash/wandb-registry-Zoo_Classifier/Datasets:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcfe28-b952-44a5-bc8e-868480bd1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)\n",
    "dataset_artifact = run.use_artifact(artifact_or_name=name, type=\"dataset\")\n",
    "local_dataset_path = dataset_artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77089d70-5248-4946-be78-ce4a87bb58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and labels into notebook\n",
    "loaded_data = torch.load(f=local_dataset_path+ \"/zoo_dataset\")\n",
    "loaded_labels = torch.load(f=local_dataset_path + \"/zoo_labels\")\n",
    "\n",
    "# using the train test split function using the same random state seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(loaded_data,loaded_labels, random_state=42,test_size=0.25, shuffle=True)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522de6d-9a30-4534-a85d-6d0faf56a2f0",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model\n",
    "\n",
    "(Noah to do, track this w/ W&B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d8aec-cd4d-4100-b186-50c7eff0bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264c840-5e69-4a2e-960b-46f09ef878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01599d26-b719-4e43-b395-1e70a77aca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "__, predicted = torch.max(outputs, 1)\n",
    "print(predicted[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c9556-726a-4c65-859d-91ebf7933e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: \"Aves\",\n",
    "    1: \"Mammalia\",\n",
    "    2: \"Reptilia\",\n",
    "    3: \"Actinopterygii\",\n",
    "    4: \"Amphibia\",\n",
    "    5: \"Insecta\",\n",
    "    6: \"Crustacea\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30698c-5231-458c-9862-dd919cbc7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(lambda x: class_labels.get(x), predicted.numpy()))\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737dc29e-03b8-441f-ab72-6ef9fa9cb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example_notebooks",
   "language": "python",
   "name": "example_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
