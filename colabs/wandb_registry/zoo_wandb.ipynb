{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381c6d14-e10d-4996-bd01-e743208644d6",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate how you and other members of your organization can use W&B Registry to track, share, and use dataset and model artifacts in your machine learning workflows. By the end of this notebook, you will know how to use W&B to:\n",
    "\n",
    "1. Use a [core registry](https://docs.wandb.ai/guides/registry/registry_types#core-registry)\n",
    "2. Create [collections](https://docs.wandb.ai/guides/registry/create_collection) within the default **Dataset** and **Model** registry\n",
    "3. Make dataset and model artifacts available to other members of your organization, and\n",
    "4. Download artifacts from the registry for inference\n",
    "\n",
    "To achieve this, we will train a neural network to identify animal classes, as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f92cd-90ff-41cc-a656-2502799a1989",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ee0c6-4e88-4c77-9cf5-dde109bb7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb torch ucimlrepo scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c6701-7375-4bb0-a70f-3fdc5bff1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import wandb\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fecd29-8146-41e2-86fb-0bb4e3e3350a",
   "metadata": {},
   "source": [
    "## Retrieve and process dataset\n",
    "We will use the open source [Zoo dataset](https://archive.ics.uci.edu/dataset/111/zoo) from the UCI Machine Learning Repository.\n",
    "\n",
    "### Retrieve dataset\n",
    "We can either manually download the dataset or use the [`ucimlrepo` package](https://github.com/uci-ml-repo/ucimlrepo) to import the dataset directly into our notebook. For this example, we will import the dataset directly into this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1fc39-c06f-468c-82ad-736ca764e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = zoo.data.features \n",
    "y = zoo.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137a521-ced5-4e35-88d0-b6245527cb90",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Let's take a quick look at the shape and data type of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb34ad-02df-4256-b5de-6058c2826305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features: \", X.shape, \"type: \", type(X))\n",
    "print(\"labels: \", y.shape, \"type: \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2f7c4-7db7-4d09-9850-e7c6121ab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4df0-120b-4915-8f88-c9d36637cbfc",
   "metadata": {},
   "source": [
    "### Process data\n",
    "\n",
    "For training let's convert our dataset from a [pandas `DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) to [a tensor with PyTorch](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor), convert the data type of our input tensor(float64 to float32) to match the data type of the `nn.Linear module`, and convert our label tensor to index from 0-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff90527-d818-4678-bf01-3efe4c8c58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type of the data must match the data type of the model, the default dtype for nn.Linear is torch.float32\n",
    "dataset = torch.tensor(X.values).type(torch.float32) \n",
    "\n",
    "# Convert to tensor and format labels from 0 - 6 for indexing\n",
    "labels = torch.tensor(y.values)  - 1\n",
    "\n",
    "print(\"dataset: \", dataset.shape, \"dtype: \",dataset.dtype)\n",
    "print(\"labels: \", labels.shape, \"dtype: \",labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce3c7c-193c-4c5a-90e6-ad278ff17154",
   "metadata": {},
   "source": [
    "Save processed dataset locally using [`torch.save`](https://pytorch.org/docs/stable/generated/torch.save.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dacfb7-7493-4d36-8167-212f8b51af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, \"zoo_dataset.pt\")\n",
    "torch.save(labels, \"zoo_labels.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2b1fb-a1af-4311-aae9-86497d00ffda",
   "metadata": {},
   "source": [
    "## Track and publish dataset \n",
    "\n",
    "Within the Dataset registry we will create a collection called \"zoo-dataset-tensors\". A collection is a set of linked artifact versions in a registry.  \n",
    "\n",
    "To create a collection we need to do two things:\n",
    "1. Specify the collection and registry we want to link our artifact version to. To do this, we specify a \"target path\" for our artifact version.\n",
    "2. Use the `run.link_artifact` method and pass our artifact object and the target path.\n",
    "\n",
    "The target path consists of the name of the organization your team belongs to, the name of the registry, and the name of the collection. There are two ways to get the target path, interatively with the W&B App UI or programmatically with the W&B Python SDK.\n",
    "\n",
    "#### Interactively get target path of a collection\n",
    "\n",
    "1. Navigate to the Registry app at https://wandb.ai/registry/\n",
    "2. Click on the registry you want to link your artifact version to.\n",
    "3. At the top of the page, you will see an autogenerated code snippet. Copy the string next to the `target_path` parameter in `run.link_artifact()`.\n",
    "\n",
    "\n",
    "#### Programmatically make the collection target path \n",
    "\n",
    "The target path of a collectin consists of three parts:\n",
    "* The name of the organization\n",
    "* The name of the registry\n",
    "* The name of the collection within the registry\n",
    "\n",
    "If you know these three fields, you can create the full name yourself with string concatanation, f-strings, and so forth:\n",
    "```python\n",
    "target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2217d9-39df-4e9a-a715-7067e9e5c731",
   "metadata": {},
   "source": [
    "### Publish tensor dataset\n",
    "\n",
    "Let's publish our dataset to the Dataset registry in a collection called \"zoo-dataset-tensors\". To do this, we will \n",
    "\n",
    "1. Get or create the target path. For this notebook we will programmatically create the target path\n",
    "1. Initialize a run\n",
    "1. Create an Artifact object\n",
    "2. Add each split dataset as individual files to the artifact object\n",
    "3. Link the artifact object to the collection with `run.link_artifact()`. Here we specify the target path and the artifact we want to link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe847c-9229-4428-873b-bde5d0c654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"Dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors\"\n",
    "\n",
    "# Path to link the artifact to a collection\n",
    "dataset_target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c237c-1e8d-4c2e-8ac4-8221146d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"zoo_experiment\"\n",
    "TEAM_ENTITY = \"smle-reg-team-2\"\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=TEAM_ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=\"publish_dataset\"\n",
    ")\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"zoo_dataset\",\n",
    "    type=\"dataset\", \n",
    "    description=\"Processed dataset and labels.\"\n",
    ")\n",
    "\n",
    "artifact.add_file(local_path=\"zoo_dataset.pt\", name=\"zoo_dataset\")\n",
    "artifact.add_file(local_path=\"zoo_labels.pt\", name=\"zoo_labels\")\n",
    "\n",
    "run.link_artifact(artifact=artifact, target_path=dataset_target_path)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383bc963-55f9-498c-b42d-a2a0bf86f3b7",
   "metadata": {},
   "source": [
    "### Split data and publish split dataset\n",
    "Split the data into a training and test set. Splitting the dataset and tracking them as separate files will make it easier for a different user to use the correct datasets for replicating our results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432936b-31bf-477b-a4aa-a3a85345e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decsribe how we split the training dataset for future reference, reproducibility.\n",
    "config = {\n",
    "    \"random_state\" : 42,\n",
    "    \"test_size\" : 0.25,\n",
    "    \"shuffle\" : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243bcd0-c3bc-4958-bb62-4ac129cbaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset,labels, \n",
    "    random_state=config[\"random_state\"],\n",
    "    test_size=config[\"test_size\"], \n",
    "    shuffle=config[\"shuffle\"]\n",
    ")\n",
    "\n",
    "# Save the files locally\n",
    "torch.save(X_train, \"zoo_dataset_X_train.pt\")\n",
    "torch.save(y_train, \"zoo_labels_y_train.pt\")\n",
    "\n",
    "torch.save(X_test, \"zoo_dataset_X_test.pt\")\n",
    "torch.save(y_test, \"zoo_labels_y_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d0992-15a9-4687-8c3b-4218bf70adb9",
   "metadata": {},
   "source": [
    "Next, let's publish this dataset into a different collection within the Dataset registry called \"zoo-dataset-tensors-split\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bacb4-5ca7-4a74-abc8-e890c655fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=TEAM_ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=\"publish_split_dataset\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Let's add a description to let others know which file to use in future experiments\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"split_zoo_dataset\",\n",
    "    type=\"dataset\", \n",
    "    description=\"Artifact contains `zoo_dataset` split into 4 datasets. \\\n",
    "                For training, use `zoo_dataset_X_train` and `zoo_labels_y_train`. \\\n",
    "                For testing, use `zoo_dataset_X_test` and `zoo_labels_y_test`.\"\n",
    ")\n",
    "\n",
    "artifact.add_file(local_path=\"zoo_dataset_X_train.pt\", name=\"zoo_dataset_X_train\")\n",
    "artifact.add_file(local_path=\"zoo_labels_y_train.pt\", name=\"zoo_labels_y_train\")\n",
    "artifact.add_file(local_path=\"zoo_dataset_X_test.pt\", name=\"zoo_dataset_X_test\")\n",
    "artifact.add_file(local_path=\"zoo_labels_y_test.pt\", name=\"zoo_labels_y_test\")\n",
    "\n",
    "REGISTRY_NAME = \"Dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors-split\"\n",
    "target_dataset_path=f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "\n",
    "run.link_artifact(artifact=artifact, target_path=target_dataset_path)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971ed7f-f1d3-4d62-b2ff-26135f45045f",
   "metadata": {},
   "source": [
    "We can verify we correctly linked our artifact to our desired collection and registry with W&B App UI: \n",
    "\n",
    "1. Navigate to the Registry App\n",
    "2. Select on the Dataset registry\n",
    "3. Click **View details** \"zoo-dataset-tensors-split\" collection\n",
    "4. Click the **View** button next to the artifact version\n",
    "5. Select the **Files** tab\n",
    "\n",
    "You should see four files: \"zoo_dataset_X_test\", \"zoo_dataset_X_train\", \"zoo_labels_y_test\", and \"zoo_labels_y_train\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3492dc4-f465-4843-b573-0b2ca752b0ac",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "The following cells show how to create a simple neural network classifier with PyTorch. There is nothing unique about this model, so we'll gloss over this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28053a-73c5-4ef4-a308-0c255c25595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=16 , out_features=16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=16, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c289cfc-eec8-49dc-8d93-9bd188c40545",
   "metadata": {},
   "source": [
    "### Define hyperparameters, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6486b-8d3a-43c6-b97e-66308b64e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epochs\": 1000,\n",
    "    \"model_type\": \"Multivariate_neural_network_classifier\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485e9d4-01db-40b2-ae3d-1c7c7d1c45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hyperparameter_config[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f6942-e8e9-4429-9f26-e00fbdf8b338",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Next, let's train, save, and store model as an artifact in W&B.  \n",
    "\n",
    "We'll train the model using the training data we published to the Dataset registry. To use the an artifact from a registry, we need to provide the name of the artifact. The name of the artifact looks similar to a filepath. In fact, this filepath is almost identical to the target path we used in a previous step to publish our artifact, except that we must specify the specific artifact version we want to use following the name of the collection: \n",
    "\n",
    "```python\n",
    "# Target path for publishing an artifact version to a registry\n",
    "f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Artifact name/filepath for downloading and using artifact publsihed in a registry\n",
    "f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "```\n",
    "\n",
    "Since we only linked on artifact version, the version we'll use is `v0`. (W&B uses 0 indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042375b-c2c8-4503-9888-a406bc9c5df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = wandb.init(entity = TEAM_ENTITY, project = PROJECT, job_type = \"training\", config = hyperparameter_config)\n",
    "\n",
    "# Get dataset artifacts from registry\n",
    "VERSION = 0\n",
    "artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME.lower()}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "dataset_artifact = run.use_artifact(artifact_or_name=artifact_name)\n",
    "\n",
    "# Download only the training data\n",
    "X_train_path = dataset_artifact.download(path_prefix=\"zoo_dataset_X_train\")\n",
    "y_train_path = dataset_artifact.download(path_prefix=\"zoo_labels_y_train\")\n",
    "\n",
    "# Load tensors \n",
    "X_train = torch.load(f=X_train_path+\"/zoo_dataset_X_train\")\n",
    "y_train = torch.load(f=y_train_path+\"/zoo_labels_y_train\")\n",
    "\n",
    "# Set initial dummy loss value to compare to in training loop\n",
    "prev_best_loss = 1e10 \n",
    "\n",
    "# Keep track of which model version for us to use at a later step\n",
    "# Set to -1 for 0 indexing\n",
    "model_version = -1\n",
    "\n",
    "# Training loop\n",
    "for e in range(hyperparameter_config[\"epochs\"] + 1):\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred, y_train.squeeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    wandb.log({\n",
    "            \"train/epoch_ndx\": e,\n",
    "            \"train/train_loss\": loss\n",
    "        })\n",
    "\n",
    "    # Checkpoint/save model if loss improves\n",
    "    if (e % 100 == 0) and (loss <= prev_best_loss):\n",
    "        print(\"epoch: \", e, \"loss:\", loss.item())\n",
    "    \n",
    "        PATH = 'zoo_wandb.pth' \n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        model_artifact_name = f\"zoo-{wandb.run.id}\"\n",
    "        artifact = wandb.Artifact(\n",
    "            name=model_artifact_name,\n",
    "            type=\"model\",\n",
    "            metadata={\n",
    "                \"num_classes\": 7,\n",
    "                \"model_type\": wandb.config[\"model_type\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Add artifact file\n",
    "        artifact.add_file(PATH)\n",
    "        artifact.save()\n",
    "\n",
    "        # Store new best loss\n",
    "        prev_best_loss = loss\n",
    "        model_version += 1\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(f\"Training complete. Model artifact {model_artifact_name}:v{model_version} contains the model with the lowest recorded loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666d37e-1232-4609-8e2c-78af670585ab",
   "metadata": {},
   "source": [
    "The preceeding cell might look intimidating. Let's break it down:\n",
    "\n",
    "* First, we download the dataset from the Dataset registry and load it as a tensor\n",
    "* Next, we create a simple training loop\n",
    "  * Within the training loop we log the loss for each step\n",
    "  * We checkpoint(save) the model every time the remainder of the epoch divided by 100 is 0 and the loss is lower than the previously recorded loss.\n",
    "  * We then add the saved PyTorch model to the Artifact. \n",
    "\n",
    "A couple of things to note:\n",
    "1. The preceeding cell stores 10 versions of the model. You can confirm this by navigating to your project workspace, select Artifacts in the left navigation, and expand the model artifact.\n",
    "2. At this point, we have only tracked the model artifact within our team's project. Anyone outside of our team does not have access to the model we created. To make this model accessible to members outside of our team, we will  need to publish our model to the registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05223ca1-3879-4f51-b843-76f1c25cf1f7",
   "metadata": {},
   "source": [
    "## Publish model to the registry\n",
    "Let's make this model artifact available to other users in our organization. To do this, we will create a collection within the Model registry.\n",
    "\n",
    "\n",
    "To create a collection within a registry, we will need to get the full name (or path) of our model artifact. There are two ways to do this, interatively with the W&B App UI or programmatically with the W&B Python SDK.\n",
    "\n",
    "### Interactively get the path of an artifact\n",
    "\n",
    "1. Navigate to the project where you logged your model artifact on the W&B App.\n",
    "1. Click on the **Artifacts** tab.\n",
    "2. Select the name of the artifact within the left navigation.\n",
    "3. Click on the **Version** tab.\n",
    "4. Within the **Version overview**, copy and paste the path next to the **Full Name** field.\n",
    "\n",
    "### Programmatically make the path of an artifact\n",
    "\n",
    "The full name (path) of an artifact consists of four components:\n",
    "* Team entity\n",
    "* Project name\n",
    "* The name of the artifact (the string you passed when you created the artifact object with `wandb.Aritfact()`)\n",
    "* The artifact version\n",
    "\n",
    "If you know these four fields, you can create the full name yourself with string concatanation, f-strings, and so forth:\n",
    "```python\n",
    "# Artifact path\n",
    "f'{TEAM_ENTITY}/{PROJECT}/{artifact_name}:v{version}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd97b93-d708-4260-ba69-d04b085a009c",
   "metadata": {},
   "source": [
    "In this example, we'll programmatically create the path since we have these values loaded into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31ddfa-53e0-4b00-b010-253eef47066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_path = f'{TEAM_ENTITY}/{PROJECT}/{model_artifact_name}:v{model_version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa9221-f6ac-454b-9a48-47597f47a572",
   "metadata": {},
   "source": [
    "Similar to how we created a target path when we published our dataset artifact to the Dataset registry, let's create a target path for our model artifact. This target path will tell W&B which collection and which registry to link our artifact version to. The target path consists of:\n",
    "\n",
    "```python\n",
    "# Target path of collection\n",
    "f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "```\n",
    "\n",
    "To do this, we will need the name of our organization, the name of the registry, and the name of the collection. If the collection does not already exist, W&B will create one for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e734592-7ab1-4baa-af04-71956a92f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"Model\"\n",
    "COLLECTION_NAME = \"Zoo_Classifier_Models\"\n",
    "\n",
    "collection_target_path=f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "print(\"Linking model artifact to: \", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ed37c-f488-4cd8-8797-fdeb6002148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)\n",
    "model_artifact = run.use_artifact(artifact_or_name=artifact_path, type=\"model\")\n",
    "run.link_artifact(artifact=model_artifact, target_path=collection_target_path)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da2c69-dc5d-451b-b709-fe2822a9811c",
   "metadata": {},
   "source": [
    "## Download artifacts from registry for inference\n",
    "\n",
    "For this last section, suppose you are in a different team than the user who uploaded the artifact. You want to retrieve the model and dataset artifact was pushed to the registry and make predictions with a new test set. Your team is called \"smle-reg-team-2\" (previously the team was \"smle-reg-team-1\") and your team is working on analyzing zoo models in a project called \"Compare_Zoo_Models\".\n",
    "\n",
    "\n",
    "Also suppose that this user has [member role permissions](https://docs.wandb.ai/guides/registry/configure_registry#registry-roles-permissions) which means they can view and download artifacts from our registry.\n",
    "\n",
    "How can you retrieve the artifacts version that were published by another user in another team? Simple:\n",
    "\n",
    "1. Get the path of the artifact version from the registry UI\n",
    "2. Use the W&B Python SDK to download the artifacts\n",
    "\n",
    "#### Interactively get path of the model and dataset artifacts \n",
    "1. Go to the W&B Registry app at https://wandb.ai/registry/.\n",
    "2. Select the registry that your artifact is linked to.\n",
    "3. Click the **View details** button next to the name of the collection with your linked artifact. \n",
    "4. Click on the **View** button next to the artifact version. \n",
    "5. Within the **Version** tab, copy and paste the path listed next to **Full Name**.\n",
    "\n",
    "\n",
    "In this notebook example, we linked our artifact version to a collection called \"Zoo_Classifier_Models\" within the **Model** registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7cfe-eef0-478d-9898-95067e37d572",
   "metadata": {},
   "source": [
    "### Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ef0828dd-4986-4077-b469-54a60b2db2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact name: smle-registries-bug-bash/wandb-registry-model/Zoo_Classifier_Models:v0\n"
     ]
    }
   ],
   "source": [
    "# Create model artifact name\n",
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"model\"\n",
    "COLLECTION_NAME = \"Zoo_Classifier_Models\"\n",
    "VERSION = 0\n",
    "\n",
    "model_artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "print(f\"Model artifact name: {model_artifact_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d258c-ed08-47f0-afca-8a2a50bb0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFERENT_TEAM_ENTITY = \"smle-reg-team-2\"\n",
    "DIFFERNT_PROJECT = \"Compare_Zoo_Models\"\n",
    "\n",
    "run = wandb.init(entity=DIFFERENT_TEAM_ENTITY, project=DIFFERNT_PROJECT)\n",
    "registry_model = run.use_artifact(artifact_or_name=model_artifact_name)\n",
    "local_model_path = registry_model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43394e-d596-4b97-947f-0314649ac0cb",
   "metadata": {},
   "source": [
    "For PyTorch models, we need to redefine our model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a3118-747d-4a44-a906-3d3eff41df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = NeuralNetwork()\n",
    "loaded_model.load_state_dict(torch.load(f=local_model_path + \"/zoo_wandb.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93895213-e75e-46e6-b3a8-8017ccaff9e2",
   "metadata": {},
   "source": [
    "### Get test dataset from registry\n",
    "\n",
    "Let's get the test dataset from our registry. Similar to before when we downloaded the training dataset from the Dataset registry, we will use a slightly modified target path to retrieve our training dataset.  (Recall that the name of the artifact looks like the target path, but has the version appended to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "55f3fa24-4865-480f-9f56-c1dde25b0141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset artifact name: smle-registries-bug-bash/wandb-registry-dataset/zoo-dataset-tensors-split:v0\n"
     ]
    }
   ],
   "source": [
    "# Create dataset artifact name\n",
    "ORG_NAME = \"smle-registries-bug-bash\"\n",
    "REGISTRY_NAME = \"dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors-split\"\n",
    "VERESION = 0\n",
    "\n",
    "data_artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "print(f\"Dataset artifact name: {data_artifact_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcfe28-b952-44a5-bc8e-868480bd1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=DIFFERENT_TEAM_ENTITY, project=DIFFERNT_PROJECT)\n",
    "dataset_artifact = run.use_artifact(artifact_or_name=data_artifact_name, type=\"dataset\")\n",
    "local_dataset_path = dataset_artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77089d70-5248-4946-be78-ce4a87bb58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data and label filenames\n",
    "test_data_filename = \"zoo_dataset_X_test\"\n",
    "test_labels_filename = \"zoo_labels_y_test\" \n",
    "\n",
    "# Load dataset and labels into notebook\n",
    "loaded_data = torch.load(f\"{local_dataset_path}/{test_data_filename}\")\n",
    "loaded_labels = torch.load(f\"{local_dataset_path}/{test_labels_filename}\")\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522de6d-9a30-4534-a85d-6d0faf56a2f0",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c9556-726a-4c65-859d-91ebf7933e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: \"Aves\",\n",
    "    1: \"Mammalia\",\n",
    "    2: \"Reptilia\",\n",
    "    3: \"Actinopterygii\",\n",
    "    4: \"Amphibia\",\n",
    "    5: \"Insecta\",\n",
    "    6: \"Crustacea\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d264c840-5e69-4a2e-960b-46f09ef878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model(loaded_data)\n",
    "__, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6e86b-eafc-45b9-80d7-01a7a36ce793",
   "metadata": {},
   "source": [
    "These integers don't mean much, let's convert them to return the animal class and store this into a pandas DataFrame for us to compare the predicted vs the true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1173dc84-0395-4b23-be84-d43a0cacd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(lambda x: class_labels.get(x), predicted.numpy()))\n",
    "true_values = list(map(lambda x: class_labels.get(x), loaded_labels.squeeze().numpy()))\n",
    "\n",
    "# Create pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Predicted': results,\n",
    "        'True values': true_values\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create new column where we compare the predicted vs true\n",
    "df[\"Predicted correctly\"] = df[\"Predicted\"] == df[\"True values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "30818967-2a5a-4302-8de9-7c4ac61377bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>True values</th>\n",
       "      <th>Predicted correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insecta</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Actinopterygii</td>\n",
       "      <td>Actinopterygii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Insecta</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Insecta</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Crustacea</td>\n",
       "      <td>Crustacea</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mammalia</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Actinopterygii</td>\n",
       "      <td>Actinopterygii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Actinopterygii</td>\n",
       "      <td>Reptilia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amphibia</td>\n",
       "      <td>Amphibia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amphibia</td>\n",
       "      <td>Amphibia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Insecta</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Aves</td>\n",
       "      <td>Aves</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Crustacea</td>\n",
       "      <td>Crustacea</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predicted     True values  Predicted correctly\n",
       "0             Aves            Aves                 True\n",
       "1             Aves            Aves                 True\n",
       "2             Aves            Aves                 True\n",
       "3             Aves            Aves                 True\n",
       "4             Aves            Aves                 True\n",
       "5          Insecta         Insecta                 True\n",
       "6             Aves            Aves                 True\n",
       "7             Aves            Aves                 True\n",
       "8             Aves            Aves                 True\n",
       "9             Aves            Aves                 True\n",
       "10  Actinopterygii  Actinopterygii                 True\n",
       "11         Insecta         Insecta                 True\n",
       "12         Insecta         Insecta                 True\n",
       "13        Mammalia        Mammalia                 True\n",
       "14       Crustacea       Crustacea                 True\n",
       "15            Aves            Aves                 True\n",
       "16            Aves            Aves                 True\n",
       "17        Mammalia        Mammalia                 True\n",
       "18  Actinopterygii  Actinopterygii                 True\n",
       "19            Aves            Aves                 True\n",
       "20  Actinopterygii        Reptilia                False\n",
       "21        Amphibia        Amphibia                 True\n",
       "22        Amphibia        Amphibia                 True\n",
       "23         Insecta         Insecta                 True\n",
       "24            Aves            Aves                 True\n",
       "25       Crustacea       Crustacea                 True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d4f2e9a5-3513-4aa8-bc38-58da3f031d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted correctly\n",
       "True     25\n",
       "False     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many predictions were wrong\n",
    "df['Predicted correctly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f0eaea82-54a6-42f9-be89-e492849ee482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of incorrect guesses on test set is: 1\n"
     ]
    }
   ],
   "source": [
    "# Count how many predictions were wrong\n",
    "count_false = (~df['Predicted correctly']).sum()\n",
    "print(\"The number of incorrect guesses on test set is:\", count_false) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737dc29e-03b8-441f-ab72-6ef9fa9cb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? Track these predictions into a project???\n",
    "# run = wandb.init(entity=DIFFERENT_TEAM_ENTITY, project=DIFFERNT_PROJECT)\n",
    "# run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example_notebooks",
   "language": "python",
   "name": "example_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
